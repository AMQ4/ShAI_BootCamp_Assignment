{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58c0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./Salaries.csv\")\n",
    "# read `Salaries` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74971398",
   "metadata": {},
   "source": [
    "### 1. Basic Data Exploration: Identify the number of rows and columns in the dataset, determine the data types of each column, and check for missing values in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc87087",
   "metadata": {},
   "source": [
    "Since `df` uses the default 0-based pandas's indexing method, we can get the # rows by getting the last index + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ddeac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of rows: 148654\n",
      "Total # of columns: 13\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total # of rows: {df.index[-1] + 1}\\nTotal # of columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f7c2a",
   "metadata": {},
   "source": [
    "#### Types of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9242ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'EmployeeName', 'JobTitle', 'BasePay', 'OvertimePay', 'OtherPay',\n",
      "       'Benefits', 'TotalPay', 'TotalPayBenefits', 'Year', 'Notes', 'Agency',\n",
      "       'Status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf00de",
   "metadata": {},
   "source": [
    "Id: unique identifier (nominal).\n",
    "\n",
    "EmployeeName, JobTitle: nominal.\n",
    "\n",
    "BasePay, OvertimePay, OtherPay, Benefits, TotalPay, TotalPayBenefits: continuous, seince they contains a fractions.\n",
    "\n",
    "Year: discrete.\n",
    "\n",
    "Notes, Status: null values, they represent missing or undefined values, they could be nominal.\n",
    "\n",
    "Agency: nominal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f266cb",
   "metadata": {},
   "source": [
    "#### Checking for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281bcc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                  False\n",
      "EmployeeName        False\n",
      "JobTitle            False\n",
      "BasePay              True\n",
      "OvertimePay          True\n",
      "OtherPay             True\n",
      "Benefits             True\n",
      "TotalPay            False\n",
      "TotalPayBenefits    False\n",
      "Year                False\n",
      "Notes                True\n",
      "Agency              False\n",
      "Status               True\n",
      "Name: Columns with missing values, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "columns_with_mv = df.isna().any()\n",
    "columns_with_mv.name = \"Columns with missing values\"\n",
    "print(columns_with_mv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb01efa",
   "metadata": {},
   "source": [
    " ### 2. Calculate basic statistics mean, median, mode, minimum, and maximum salary, determine the range of salaries, and find the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73026f45",
   "metadata": {},
   "source": [
    "- Descriptive stat. for numerical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f204bf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             BasePay    OvertimePay       OtherPay       Benefits  \\\n",
      "count  148045.000000  148650.000000  148650.000000  112491.000000   \n",
      "mean    66325.448840    5066.059886    3648.767297   25007.893151   \n",
      "std     42764.635495   11454.380559    8056.601866   15402.215858   \n",
      "min      -166.010000      -0.010000   -7058.590000     -33.890000   \n",
      "25%     33588.200000       0.000000       0.000000   11535.395000   \n",
      "50%     65007.450000       0.000000     811.270000   28628.620000   \n",
      "75%     94691.050000    4658.175000    4236.065000   35566.855000   \n",
      "max    319275.010000  245131.880000  400184.250000   96570.660000   \n",
      "\n",
      "            TotalPay  TotalPayBenefits           Year  Notes  Status  \n",
      "count  148654.000000     148654.000000  148654.000000    0.0     0.0  \n",
      "mean    74768.321972      93692.554811    2012.522643    NaN     NaN  \n",
      "std     50517.005274      62793.533483       1.117538    NaN     NaN  \n",
      "min      -618.130000       -618.130000    2011.000000    NaN     NaN  \n",
      "25%     36168.995000      44065.650000    2012.000000    NaN     NaN  \n",
      "50%     71426.610000      92404.090000    2013.000000    NaN     NaN  \n",
      "75%    105839.135000     132876.450000    2014.000000    NaN     NaN  \n",
      "max    567595.430000     567595.430000    2014.000000    NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.drop(columns=[\"Id\"]).describe(include=[\"number\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c671c10",
   "metadata": {},
   "source": [
    "- Descriptive stat. for categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c5d6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EmployeeName          JobTitle         Agency\n",
      "count        148654            148654         148654\n",
      "unique       110811              2159              1\n",
      "top       Kevin Lee  Transit Operator  San Francisco\n",
      "freq             13              7036         148654\n"
     ]
    }
   ],
   "source": [
    "print(df.describe(include=[\"object\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69747727",
   "metadata": {},
   "source": [
    "### 3. Handle missing data by suitable method with explain why you use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f3c6b",
   "metadata": {},
   "source": [
    "Well, there are many methods and techniques to deal with missing values, and the most appropriate thing to consider when dealing with missing values is to go back to our stakeholders and ask them how to deal with these missing values.\n",
    "\n",
    "Let's take a closer look at the missing data, to see the appropriate way to handle each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b267f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasePay           609\n",
       "OvertimePay         4\n",
       "OtherPay            4\n",
       "Benefits        36163\n",
       "Notes          148654\n",
       "Status         148654\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, columns_with_mv].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2316af",
   "metadata": {},
   "source": [
    "Assuming that all missing values are missing completely at random(MCAR) or missing at random(MAR), we can:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b5089d",
   "metadata": {},
   "source": [
    "- **Row/Column Deletion**:\n",
    "  This has some repercussions, such as loss of information, impact on statistical calculations, and, of course, it will introduce bias. So, this method is feasible only when large datasets are available, and missing values occur only in a small percentage relative to the dataset size, like in case of `OvertimePay`, `OtherPay` and `BasePay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afedcaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"OvertimePay\", \"OtherPay\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd6f8fb",
   "metadata": {},
   "source": [
    "    For both `Notes` and `Status` null columns, it may be reasonable to consider removing them, as they do not provide meaningful information for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f177a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Status\", \"Notes\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeaa4b4",
   "metadata": {},
   "source": [
    "- **Imputation**:\n",
    "  Imputation involves filling in missing data, typically done by using measures like the mean, median, mode, neighboring values, or predictive modeling techniques.\n",
    "\n",
    "  When dealing with missing values, it's important to be keep in mind the potential biases introduced by using the mean, especially when a large number of values are missing (e.g. useing the mean for impute missing values in the `Benefits` column), as this could skew the central tendency of the data and lead to inaccuracies. \n",
    "  \n",
    "  In such cases, choosing the median can offer a more robust representation, especially as it is not influenced by outliers. While it's a common practice to calculate subgroup means/medians for imputation, but for simplicity, I'll use the overall mean/median. Additionally, for categorical attributes, relying on the mode is generally the recommended approach.\n",
    "\n",
    "  The decision between mean and median depends on various factors, one of which involves **assessing skewness**. For example, when examining the skewness of the `BasePay` column and finding a skewness value of approximately 0.42—indicating a nearly symmetric distribution—the choice between mean and median for handling missing values becomes more easy. Given the almost symmetrical nature of the distribution,choosing for the mean to substitute missing values is a suitable choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f23abaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "β = 0.42\n"
     ]
    }
   ],
   "source": [
    "print(\"β = {0:.2}\".format(df[\"BasePay\"].skew()))\n",
    "df[\"BasePay\"].fillna(df[\"BasePay\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391cb0b7",
   "metadata": {},
   "source": [
    "    Finally, let's handle the missing values in the `Benefits` column of our dataset. Since the number of missing values is relatively large compared to the total size, traditional imputation methods like using the mean or median might not be suitable. Instead, employing the linear regression algorithm seems promising.\n",
    "    It assumes a linear relationship between the target variable and the other features. By training a linear regression model on the instances where the Benefits column is not missing, we can use this model to predict and impute the missing values based on the observed relationships in the data. This makes it a suitable choice for our scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee38ef1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 3.5e+04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "df_not_missing, df_missing = (\n",
    "    df.loc[df[\"Benefits\"].notna(), df.columns.difference([\"Id\", \"EmployeeName\", \"Agency\", \"Year\"])],\n",
    "    df.loc[df[\"Benefits\"].isna(), df.columns.difference([\"Id\", \"EmployeeName\", \"Agency\", \"Benefits\", \"Year\"])]\n",
    ")\n",
    "\n",
    "df_not_missing.loc[:, \"JobTitle\"] = df_not_missing[\"JobTitle\"].map(df_not_missing[\"JobTitle\"].value_counts().to_dict())\n",
    "df_missing.loc[:, \"JobTitle\"] = df_missing[\"JobTitle\"].map(df_missing[\"JobTitle\"].value_counts().to_dict())\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df_not_missing.drop(columns=[\"Benefits\"]), df_not_missing.Benefits)\n",
    "xtrain = xtrain.sub(xtrain.mean()).div(xtrain.std())\n",
    "xtest = xtest.sub(xtest.mean()).div(xtest.std())\n",
    "model.fit(xtrain, ytrain)\n",
    "ypredict = model.predict(xtest)\n",
    "\n",
    "print(\"MSE = {0:.2}\".format(mean_squared_error(ytest, ypredict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a9aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df_missing.sub(df_missing.mean()).div(df_missing.std())\n",
    "ypredict = model.predict(df_missing)\n",
    "cleaned_benefits = pd.DataFrame(ypredict, index=df_missing.index, columns=[\"Benefits\"])\n",
    "df = df.combine_first(cleaned_benefits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe5d5e",
   "metadata": {},
   "source": [
    "Quick check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "556551b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agency              False\n",
       "BasePay             False\n",
       "Benefits            False\n",
       "EmployeeName        False\n",
       "Id                  False\n",
       "JobTitle            False\n",
       "OtherPay            False\n",
       "OvertimePay         False\n",
       "TotalPay            False\n",
       "TotalPayBenefits    False\n",
       "Year                False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fde72d",
   "metadata": {},
   "source": [
    "Well, the absence of detailed information regarding data sources, coupled with a lack of guidance on managing missing values and distinguishing between correct and incorrect data values, complicates the data cleaning process. \n",
    "\n",
    "Please, refer to *doi* research papers below for more information about how I deal with this task:  \n",
    "10.20470/JSI.V5I1.178  \n",
    "10.1111/j.1741-3737.2005.00191\n",
    "\n",
    "or follow these links:  \n",
    "https://rb.gy/wjiwmb <br>\n",
    "https://rb.gy/le1m0o\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a4414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
